###### generated by PhPy.py ######
import random
import time
import sys

from phpLibrary import *
#SF_ROOT_DIR = realpath('/opt/kaltura/app/alpha')
SF_APP = 'kaltura'
SF_ENVIRONMENT = 'batch'
SF_DEBUG = True

#from bootstrap import *
from sortedArray import *

#*******************************************************
# *		Utility functions
# *******************************************************
def debugLog(debugMsg):
    global currentTime, PARAMETERS
    if (PARAMETERS['debugLogEnabled']):
        sys.stdout.write("%s: %s\n" % (currentTime, debugMsg))
        
    
def endswith(string, test):
    testlen = len(test)
    if (testlen > len(string)):
        return False
        
    return string[-testlen:] == test
    
def valueOrNull(array, key):
    if (array.has_key(key)):
        return array[key]
        
    return None
    
def intOrNull(array, key):
    if (array.has_key(key)):
        return int(array[key])
        
    return None

#*******************************************************
# *		Database functions
# *******************************************************
def initializePropel():
    ilreplConfig = {'classname' : 'KalturaPDO',
		'phptype' : 'mysql',
		'database' : 'kaltura',
		'hostspec' : 'ilrepl.kaltura.dev',
		'user' : 'kaltura',
		'password' : 'kaltura',
		'dsn' : 'mysql:host=ilrepl.kaltura.dev;port=3306;dbname=kaltura;user=kaltura;password=kaltura;',}
    localConfig = {'classname' : 'KalturaPDO',
		'phptype' : 'mysql',
		'database' : 'kaltura',
		'hostspec' : 'localhost',
		'user' : 'root',
		'password' : '',
		'dsn' : 'mysql:host=localhost;port=3306;dbname=kaltura;user=root;password=;',}
    dbConfig = {'datasources' : 
		{'default' : 'propel',	 
			'propel' : 
			{'adapter' : 'mysql',
				'connection' : 
				localConfig,},},}
    Propel.setConfiguration(dbConfig)
    Propel.setLogger(KalturaLog.getInstance())
    Propel.initialize()
    
def enumBatchJobs(startTime, endTime, callback):
    global PARAMETERS
    curTime = startTime
    while (curTime < endTime):
        nextTime = (curTime + 24 * 60 * 60)
        queryStart = time.strftime('%Y-%m-%d', time.localtime(curTime))
        queryEnd = time.strftime('%Y-%m-%d', time.localtime(nextTime))
        curTime = time.strftime('%Y-%m-%d %H:%M:%S')
        memUsage = memory_get_usage()
        sys.stdout.write("%s Running query %s - %s... (Mem=%s)\n" % (curTime, queryStart, queryEnd, memUsage))
        criteria = Criteria()
        criteria.addAnd(BatchJobPeer.CREATED_AT, queryStart, Criteria.GREATER_EQUAL)
        criteria.addAnd(BatchJobPeer.CREATED_AT, queryEnd, Criteria.LESS_THAN)
        criteria.addAnd(BatchJobPeer.JOB_TYPE, BatchJobType.CONVERT, Criteria.EQUAL)
        if (PARAMETERS['simulatedSchedulerIds'] != 'all'):
            criteria.addAnd(BatchJobPeer.LAST_SCHEDULER_ID, PARAMETERS['simulatedSchedulerIds'], Criteria.IN)
            
        criteria.addAscendingOrderByColumn(BatchJobPeer.CREATED_AT)
        batchJobs = BatchJobPeer.doSelect(criteria)
        curTime = time.strftime('%Y-%m-%d %H:%M:%S')
        memUsage = memory_get_usage()
        batchJobCount = len(batchJobs)
        sys.stdout.write("%s Processing %s query results... (Mem=%s)\n" % (curTime, batchJobCount, memUsage))
        for batchJob in batchJobs:
            callback(batchJob)
            
        BatchJobPeer.clearInstancePool()
        mediaInfoPeer.clearInstancePool()
        
        curTime = nextTime
    
def getRunningJobs(currentTime):
    global PARAMETERS
    criteria = Criteria()
    # queue time/finish time are not indexed, use createdAt to limit the search (more than 90% of the jobs complete within 7hrs)
    minCreatedAtStr = time.strftime('%Y-%m-%d', time.localtime(currentTime - 24 * 3600))
    currentTimeStr = time.strftime('%Y-%m-%d', time.localtime(currentTime))
    criteria.addAnd(BatchJobPeer.JOB_TYPE, BatchJobType.CONVERT, Criteria.EQUAL)
    criteria.addAnd(BatchJobPeer.CREATED_AT, minCreatedAtStr, Criteria.GREATER_EQUAL)
    criteria.addAnd(BatchJobPeer.CREATED_AT, currentTimeStr, Criteria.LESS_THAN)
    criteria.addAnd(BatchJobPeer.QUEUE_TIME, currentTimeStr, Criteria.LESS_THAN)
    criteria.addAnd(BatchJobPeer.FINISH_TIME, currentTimeStr, Criteria.GREATER_THAN)
    if (PARAMETERS['simulatedSchedulerIds'] != 'all'):
        criteria.addAnd(BatchJobPeer.LAST_SCHEDULER_ID, PARAMETERS['simulatedSchedulerIds'], Criteria.IN)
        
    criteria.addAscendingOrderByColumn(BatchJobPeer.QUEUE_TIME)
    batchJobs = BatchJobPeer.doSelect(criteria)
    return batchJobs
    
def printRunningJobsInfo(currentTime):
    runningJobs = getRunningJobs(currentTime)
    runningJobsCount = len(runningJobs)
    sys.stdout.write("Running jobs\n=-=-=-=-=-=-=-=-=-=\n")
    sys.stdout.write("count=%s\n" % (runningJobsCount))
    for dcIndex in xrange(2):
        sys.stdout.write("=== DC %s\n" % (dcIndex))
        dcJobCount = 0
        for runningJob in runningJobs:
            if (runningJob.getDc() != dcIndex):
                continue
                
            dcJobCount += 1
            id = runningJob.getId()
            executionTimeLeft = runningJob.getFinishTime(None) - currentTime
            sys.stdout.write("	Job %s timeLeft=%s\n" % (id, executionTimeLeft))
            
        sys.stdout.write("	Count=%s\n" % (dcJobCount))
        
    
#*******************************************************
# *		Statistics
# *******************************************************
class Categorizer:
    @staticmethod
    def getCategories(batchJob, isActualResults, firstFlavorOfEntry = False):
        global PARAMETERS
        if (PARAMETERS.has_key('filterCallback')):
            if (not PARAMETERS['filterCallback']( batchJob)):
                return []
                
            
        categories = PARAMETERS['categories']
        result = []
        dc = batchJob.getDc()
        if ('all' in categories):
            result.append('all')
            
        if ('dc' in categories):
            result.append("dc_%s" % (dc))
            
        if ('prio' in categories):
            prio = batchJob.getPriority()
            result.append("prio_%s" % (prio))
            
        if ('dcprio' in categories):
            prio = batchJob.getPriority()
            result.append("dc_%s_prio_%s" % (dc, prio))
            
        if ('duration' in categories):
            durationInMins = int(batchJob.duration / 60)
            durationGroup = None
            for curDuration in PARAMETERS['durationGroups']:
                if (durationInMins < curDuration):
                    durationGroup = curDuration
                    break
                    
                
            if (durationGroup == None):
                result.append('duration_other')
                
            else:
                result.append("duration_%s" % (durationGroup))
                
            
        if ('time' in categories):
            dateInfo = getdate(batchJob.getCreatedAt(null))
            result.append(sprintf('time_%s_%02d_%02d', dc, dateInfo['mday'], dateInfo['hours']))
            
        if ('day' in categories):
            dateInfo = getdate(batchJob.getCreatedAt(null))
            result.append(sprintf('day_%s_%04d_%02d_%02d', dc, dateInfo['year'], dateInfo['mon'], dateInfo['mday']))
            
        partnerId = batchJob.getPartnerId()
        if ("pid_%s" % (partnerId) in categories):
            result.append("pid_%s" % (partnerId))
            
        for cat in categories:
            if (cat[:7] == 'notpid_' and cat != "notpid_%s" % (partnerId)):
                result.append(cat)
                
            
        if ('ff' in categories and 
			firstFlavorOfEntry):
            ffCats = []
            for cat in result:
                ffCats.append("%s_FF" % (cat))
                
            result = result + ffCats
            
        if ('sched' in categories and
			isActualResults):
            lastSchedId = batchJob.getLastSchedulerId()
            result.append("sched_%s" % (lastSchedId))
            
        return result
        
    
class SimpleVariable:
    def __init__(self):
        self.value = None
        
    def setValue(self, value):
        self.value = value
        
    def getMeasures(self):
        return {'value' : self.value}
        
    
class VariableAnalysis:
    def __init__(self, histMinValue, histMaxValue, histResolution):
        # min / max
        self.minValue = None
        self.maxValue = None
        # average
        self.sampleCount = 0
        self.sampleSum = 0
        # histogram
        self.histogram = {}
        self.histMinValue = histMinValue
        self.histMaxValue = histMaxValue
        self.histResolution = histResolution
        
    def addSample(self, value, weight=1):
        # min / max
        if (self.minValue == None or value < self.minValue):
            self.minValue = value
            
        if (self.maxValue == None or value > self.maxValue):
            self.maxValue = value
            
        # average
        self.sampleCount += weight
        self.sampleSum += value * weight
        # histogram
        if (value < self.histMinValue):
            histIndex = -1
            
        elif (value >= self.histMaxValue):
            histIndex = self.histResolution
            
        else:
            histIndex = int((value - self.histMinValue) * self.histResolution / (self.histMaxValue - self.histMinValue))
            
        if (self.histogram.has_key(histIndex)):
            self.histogram[histIndex] += weight
            
        else:
            self.histogram[histIndex] = weight
            
        
    def getMeasures(self):
        result = {}
        # min / max
        result['min'] = self.minValue
        result['max'] = self.maxValue
        # average
        average = 0
        if (self.sampleCount != 0):
            average = self.sampleSum / self.sampleCount
            
        result['average'] = average
        result['samples'] = self.sampleCount
        # histogram
        maxIndex = self.histResolution
        while maxIndex >= -1 and not self.histogram.has_key(maxIndex):
            maxIndex -= 1

        hist = ''
        for histIndex in xrange(-1, maxIndex + 1):
            if (self.histogram.has_key(histIndex)):
                curValue = self.histogram[histIndex]
                
            else:
                curValue = 0
                
            hist += "%s " % (curValue)
            
        result['hist'] = hist
        return result
        
    
class JobVariableSet:
    def __init__(self, category):
        self.category = category
        self.currentRunningJobs = 0
        self.lastRunningJobsUpdateTime = None
        self.currentQueuedJobs = 0
        self.lastQueuedJobsUpdateTime = None
        self.dummyJobCount = 0
        self.variables = {'waitTime' : VariableAnalysis(0, 20000, 100),
			'processTime' : VariableAnalysis(0, 10000, 100),
			'completionTime' : VariableAnalysis(0, 25000, 100),
			'relWaitTime' : VariableAnalysis(0, 2000, 100),
			'relCompletionTime' : VariableAnalysis(0, 4000, 400),
			'executionAttempts' : VariableAnalysis(0, 10, 10),
			'runningJobs' : VariableAnalysis(0, 100, 100),
			'queuedJobs' : VariableAnalysis(0, 100, 100),
			'dummyJobQueueTime' : SimpleVariable(),
			'dummyJobCompleteTime' : SimpleVariable(),}
        
    def updateRunningJobsCount(self, increment, currentTime):
        if (self.lastRunningJobsUpdateTime != None and
			currentTime > self.lastRunningJobsUpdateTime):
            weight = currentTime - self.lastRunningJobsUpdateTime
            self.variables['runningJobs'].addSample(self.currentRunningJobs, weight)
            
        self.currentRunningJobs += increment
        self.lastRunningJobsUpdateTime = currentTime
        
    def updateQueuedJobsCount(self, increment, currentTime):
        if (self.lastQueuedJobsUpdateTime != None and
			currentTime > self.lastQueuedJobsUpdateTime):
            weight = currentTime - self.lastQueuedJobsUpdateTime
            self.variables['queuedJobs'].addSample(self.currentQueuedJobs, weight)
            
        self.currentQueuedJobs += increment
        self.lastQueuedJobsUpdateTime = currentTime
        
    def notifyJobQueued(self, batchJob, jobQueueTime):
        global currentTime, PARAMETERS
        self.updateQueuedJobsCount(1, jobQueueTime)
        if (PARAMETERS.has_key('dummyPartnerId') and 
			batchJob.getPartnerId() == PARAMETERS['dummyPartnerId']):
            if (self.dummyJobCount == 0):
                self.variables['dummyJobQueueTime'].setValue(currentTime)
                
            self.dummyJobCount += 1
            
        
    def notifyJobStarted(self, batchJob, jobStartTime):
        self.updateQueuedJobsCount(-1, jobStartTime)
        self.updateRunningJobsCount(1, jobStartTime)
        
    def notifyJobCompleted(self, batchJob, jobStartTime, jobEndTime):
        global currentTime, PARAMETERS
        self.updateRunningJobsCount(-1, jobEndTime)
        if (PARAMETERS.has_key('dummyPartnerId') and 
			batchJob.getPartnerId() == PARAMETERS['dummyPartnerId']):
            self.dummyJobCount -= 1
            if (self.dummyJobCount == 0):
                self.variables['dummyJobCompleteTime'].setValue(currentTime)
                
            
        if (jobStartTime > batchJob.getCreatedAt(None)):
            waitTime = jobStartTime - batchJob.getCreatedAt(None)
            
        else:
            waitTime = 0
            
        if (jobEndTime > jobStartTime):
            processTime = jobEndTime - jobStartTime
            
        else:
            processTime = 0
            
        completionTime = waitTime + processTime
        if (processTime >= PARAMETERS['minProcessTime']):
            relWaitTime = waitTime / processTime
            
        else:
            relWaitTime = waitTime / PARAMETERS['minProcessTime']
            
        if (batchJob.duration >= PARAMETERS['minDuration']):
            relCompletionTime = completionTime / batchJob.duration
            
        else:
            relCompletionTime = completionTime / PARAMETERS['minDuration']
            
        variables = {'waitTime' : waitTime,
			'processTime' : processTime,
			'completionTime' : completionTime,
			'relWaitTime' : relWaitTime,
			'relCompletionTime' : relCompletionTime,
			'executionAttempts' : batchJob.getExecutionAttempts(),
			'duration' : batchJob.duration,}
        if (PARAMETERS.has_key('statsCallback')):
            PARAMETERS['statsCallback']( 
				self.category,
				batchJob,
				variables)
            
        for (var, value) in variables.items():
            if (self.variables.has_key(var)):
                self.variables[var].addSample(value)
                
            
        
    def getVars(self):
        return self.variables.keys()
        
    def getMeasures(self, var):
        if (not self.variables.has_key(var)):
            return {}
            
        return self.variables[var].getMeasures()
        
    
DAY_SECS = 60 * 60 * 24
class SeenEntryIds:
    def __init__(self):
        self.entryIdsQueue = {}
        self.lastQueueIndex = None
        
    def wasEntrySeen(self, entryId):
        for curQueue in self.entryIdsQueue.values():
            if (entryId in curQueue):
                return True
                
            
        return False
        
    def addEntryId(self, entryId, currentTime):
        timeInDays = int(currentTime / DAY_SECS)
        queueIndex = timeInDays % 4
        if (self.lastQueueIndex != queueIndex):
            self.entryIdsQueue[queueIndex] = []
            
        self.entryIdsQueue[queueIndex].append(entryId)
        self.lastQueueIndex = queueIndex
        
    
class Statistics:
    def __init__(self, name):
        self.varSets = {}
        self.name = name
        self.isActualResults = (self.name == 'Actual')
        self.seenEntryIds = SeenEntryIds()
        
    def notifyJobQueued(self, batchJob, jobQueueTime):
        dc = batchJob.getDc()
        batchId = batchJob.getId()
        debugLog("Stats %s: job queued queueTime=%s dc=%s id=%s" % (self.name, jobQueueTime, dc, batchId))
        cats = Categorizer.getCategories(batchJob, self.isActualResults)
        for cat in cats:
            if (not self.varSets.has_key(cat)):
                self.varSets[cat] = JobVariableSet(cat)
                
            self.varSets[cat].notifyJobQueued(batchJob, jobQueueTime)
            
        
    def notifyJobStarted(self, batchJob, jobStartTime):
        dc = batchJob.getDc()
        batchId = batchJob.getId()
        debugLog("Stats %s: job started startTime=%s dc=%s id=%s" % (self.name, jobStartTime, dc, batchId))
        cats = Categorizer.getCategories(batchJob, self.isActualResults)
        for cat in cats:
            if (not self.varSets.has_key(cat)):
                self.varSets[cat] = JobVariableSet(cat)
                
            self.varSets[cat].notifyJobStarted(batchJob, jobStartTime)
            
        
    def notifyJobCompleted(self, batchJob, jobStartTime, jobEndTime):
        dc = batchJob.getDc()
        batchId = batchJob.getId()
        debugLog("Stats %s: job completed compTime=%s dc=%s id=%s" % (self.name, jobEndTime, dc, batchId))
        firstFlavorOfEntry = False
        entryId = batchJob.getEntryId()
        if (not self.seenEntryIds.wasEntrySeen(entryId)):
            self.seenEntryIds.addEntryId(entryId, jobEndTime)
            firstFlavorOfEntry = True
            
        cats = Categorizer.getCategories(batchJob, self.isActualResults, firstFlavorOfEntry)
        for cat in cats:
            if (not self.varSets.has_key(cat)):
                self.varSets[cat] = JobVariableSet(cat)
                
            self.varSets[cat].notifyJobCompleted(batchJob, jobStartTime, jobEndTime)
            
        
    def getCats(self):
        return self.varSets.keys()
        
    def getVars(self):
        result = []
        for varSet in self.varSets.values():
            result = result + varSet.getVars()
            
        return list(set(result))
        
    def getMeasures(self, cat, var):
        if (not self.varSets.has_key(cat)):
            return {}
            
        return self.varSets[cat].getMeasures(var)
        
    
#*******************************************************
# *		Batch machines and data centers
# *******************************************************
class BatchMachine:
    def __init__(self, machineType):
        self.machineParams = {}
        for paramVal in machineType.split(','):
            explodedParamVal = paramVal.split('=')
            if (len(explodedParamVal) == 1):
                self.machineParams[explodedParamVal[0]] = None
                
            elif (len(explodedParamVal) == 2):
                self.machineParams[explodedParamVal[0]] = explodedParamVal[1]
                
            
        self.minFileSize = intOrNull(self.machineParams, 'minFileSize')
        self.maxFileSize = intOrNull(self.machineParams, 'maxFileSize')
        self.minDuration = intOrNull(self.machineParams, 'minDuration')
        self.maxDuration = intOrNull(self.machineParams, 'maxDuration')
        self.maxPriority = intOrNull(self.machineParams, 'maxPriority')
        self.curJob = None
        self.jobStartTime = None
        self.jobCompleteTime = None
        
    def isIdle(self):
        return (self.curJob == None)
        
    def startJob(self, batchJob, jobExecutionTimeCallback = None):
        global currentTime, stats

        assert(self.isIdle())
        if (batchJob.getFinishTime(None) > batchJob.getQueueTime(None)):
            jobExecutionTime = batchJob.getFinishTime(None) - batchJob.getQueueTime(None)
            
        else:
            jobExecutionTime = 0
            
        if (jobExecutionTimeCallback != None):
            jobExecutionTime = jobExecutionTimeCallback(batchJob, jobExecutionTime)
            
        self.curJob = batchJob
        self.jobStartTime = currentTime
        self.jobCompleteTime = currentTime + jobExecutionTime
        stats.notifyJobStarted(batchJob, self.jobStartTime)
        
    def getNextCompleteTime(self):
        return self.jobCompleteTime
        
    def updateStatus(self):
        global currentTime, stats
        if (self.jobCompleteTime == None):
            return False
            
        if (self.jobCompleteTime > currentTime):
            return False
            
        stats.notifyJobCompleted(self.curJob, self.jobStartTime, self.jobCompleteTime)
        self.curJob = None
        self.jobStartTime = None
        self.jobCompleteTime = None
        return True
        
    def done(self):
        assert(self.isIdle())
        
    
class DataCenter:
    def __init__(self, dcTopology, dcIndex):
        self.machines = []
        self.idleMachines = []
        self.activeMachines = []
        for machineSpec in dcTopology:
            for curInd in xrange(machineSpec['count']):
                newMachine = BatchMachine(machineSpec['type'])
                self.machines.append(newMachine)
                self.idleMachines.append(newMachine)
                
            
        self.dcIndex = dcIndex
        
    def getNextCompleteTime(self):
        result = None
        for batchMachine in self.activeMachines:
            curTime = batchMachine.getNextCompleteTime()
            if (curTime == None):
                continue
                
            if (result == None or curTime < result):
                result = curTime
                
            
        return result
        
    def updateStatus(self):
        for index in xrange(len(self.activeMachines) - 1, 0 - 1, -1):
            batchMachine = self.activeMachines[index]
            if (batchMachine.updateStatus()):
                self.activeMachines.pop(index)
                self.idleMachines.append(batchMachine)
                
            
        
    def done(self):
        for batchMachine in self.machines:
            batchMachine.done()
            
        
    def scheduleJobs(self, callback, context):
        for index in xrange(len(self.idleMachines) - 1, 0 - 1, -1):
            batchMachine = self.idleMachines[index]
            (curJob, continueLoop) = callback( context, self.dcIndex, batchMachine)
            if (curJob != None):
                batchMachine.startJob(curJob)
                self.idleMachines.pop(index)
                self.activeMachines.append(batchMachine)
                
            if (not continueLoop):
                break
                
            
        
    
class DataCenters:
    def __init__(self, dcsTopology):
        self.dataCenters = {}
        self.name = dcsTopology['name']
        for (dcIndex, dcTopology) in dcsTopology.items():
            if (not type(dcIndex) == type(0)):
                continue
                
            self.dataCenters[dcIndex] = DataCenter(dcTopology, dcIndex)
            
        
    def getNextCompleteTime(self):
        result = None
        for dataCenter in self.dataCenters.values():
            curTime = dataCenter.getNextCompleteTime()
            if (curTime == None):
                continue
                
            if (result == None or curTime < result):
                result = curTime
                
            
        return result
        
    def updateStatus(self):
        for dataCenter in self.dataCenters.values():
            dataCenter.updateStatus()
            
        
    def done(self):
        for dataCenter in self.dataCenters.values():
            dataCenter.done()
            
        
    
#*******************************************************
# *		Schedulers
# *******************************************************
def getMatchingJobCB(curJob, batchMachine):
    if (batchMachine.minFileSize != None and 
		curJob.getFileSize() < batchMachine.minFileSize):
        return SortedArray.FAW_CONTINUE
        
    if (batchMachine.maxFileSize != None and 
		curJob.getFileSize() > batchMachine.maxFileSize):
        return SortedArray.FAW_CONTINUE
        
    if (batchMachine.minDuration != None and 
		curJob.duration < batchMachine.minDuration):
        return SortedArray.FAW_CONTINUE
        
    if (batchMachine.maxDuration != None and 
		curJob.duration > batchMachine.maxDuration):
        return SortedArray.FAW_CONTINUE
        
    if (batchMachine.maxPriority != None and 
		curJob.getPriority() > batchMachine.maxPriority):
        return SortedArray.FAW_CONTINUE
        
    return SortedArray.FAW_STOP_REMOVE
    
def extractFirstMatchingJob(queue, batchMachine):
    for queueIndex in xrange(len(queue)):
        curJob = queue[queueIndex]
        if (getMatchingJobCB(curJob, batchMachine) == FAW_CONTINUE):
            continue
            
        queue.pop(queueIndex)
        return curJob
        
    return None
    
class ExistingJobScheduler:
#WARNING: passing args by reference not supported (&$schedParams)
#WARNING: passing args by reference not supported (&$dataCenters)
    def __init__(self, schedParams, dataCenters):
        self.jobQueue = {0 : SortedArray(ExistingJobScheduler.getJobPriority),
			1 : SortedArray(ExistingJobScheduler.getJobPriority)}
        self.dataCenters = dataCenters
        if (schedParams.has_key('prio')):
            self.prio = schedParams['prio']
            
        else:
            self.prio = False
            
        
    @staticmethod
    def getJobPriority(object, context):
        return object.getPriority()
        
    def queueJob(self, batchJob):
        dc = int(batchJob.getDc())
        if (self.prio):
            self.jobQueue[dc].insert(batchJob, batchJob.getPriority() + 0+5)
            
        else:
            self.jobQueue[dc].insertTail(batchJob)
            
        
    def run(self):
        for (dcIndex, dataCenter) in self.dataCenters.dataCenters.items():
            dataCenter.scheduleJobs(ExistingJobScheduler.queueJobs, self)
            
        
    @staticmethod
    def queueJobs(scheduler, dcIndex, batchMachine):
        curJob = scheduler.jobQueue[dcIndex].walk(getMatchingJobCB, batchMachine)
        continueLoop = (scheduler.jobQueue[dcIndex].getCount() != 0)
        return [curJob, continueLoop]
        
    def done(self):
        for subQueue in self.jobQueue.values():
            assert(subQueue.getCount() == 0)
            
        
    
class ShorterJobsFirstScheduler:
#WARNING: passing args by reference not supported (&$schedParams)
#WARNING: passing args by reference not supported (&$dataCenters)
    def __init__(self, schedParams, dataCenters):
        self.jobQueue = {0 : SortedArray(ShorterJobsFirstScheduler.getJobProcessTime),
			1 : SortedArray(ShorterJobsFirstScheduler.getJobProcessTime)}
        self.dataCenters = dataCenters
        
    @staticmethod
    def getJobProcessTime(object, context):
        return object.getFinishTime(None) - object.getQueueTime(None)
        
    def queueJob(self, batchJob):
        dc = int(batchJob.getDc())
        self.jobQueue[dc].insert(batchJob)
        
    def run(self):
        for (dcIndex, dataCenter) in self.dataCenters.dataCenters.items():
            dataCenter.scheduleJobs(ShorterJobsFirstScheduler.queueJobs, self)
            
        
    @staticmethod
    def queueJobs(scheduler, dcIndex, batchMachine):
        curJob = scheduler.jobQueue[dcIndex].walk(getMatchingJobCB, batchMachine)
        continueLoop = (scheduler.jobQueue[dcIndex].getCount() != 0)
        return [curJob, continueLoop]
        
    def done(self):
        for subQueue in self.jobQueue.values():
            assert(subQueue.getCount() == 0)
            
        
    
class ShorterVideosFirstScheduler:
#WARNING: passing args by reference not supported (&$schedParams)
#WARNING: passing args by reference not supported (&$dataCenters)
    def __init__(self, schedParams, dataCenters):
        self.prioFactors = valueOrNull(schedParams, 'prio')
        self.jobQueue = {0 : SortedArray(ShorterVideosFirstScheduler.getVideoDuration, self.prioFactors),
			1 : SortedArray(ShorterVideosFirstScheduler.getVideoDuration, self.prioFactors)}
        self.dataCenters = dataCenters
        self.jobExecutionTimeCallback = valueOrNull(schedParams, 'jobExecutionTimeCallback')
        self.queuedJobsPerPriority = {0:{}, 1:{}}
        self.shortVideoDuration = 600
        self.queuedShortVideoJobs = {0:0, 1:0}
        
    @staticmethod
    def getVideoDuration(object, prioFactors):
        if (prioFactors == None):
            return object.duration
            
        else:
            return object.duration * prioFactors[object.getPriority()]
            
        
    def queueJob(self, batchJob):
        dc = int(batchJob.getDc())
        prio = batchJob.getPriority()
        if (self.queuedJobsPerPriority[dc].has_key(prio)):
            self.queuedJobsPerPriority[dc][prio] += 1
            
        else:
            self.queuedJobsPerPriority[dc][prio] = 1
            
        if (batchJob.duration <= self.shortVideoDuration):
            self.queuedShortVideoJobs[dc] += 1
            
        if (self.prioFactors != None and self.prioFactors[prio] == 1000000):
            self.jobQueue[dc].insertTail(batchJob)
            
        else:
            self.jobQueue[dc].insert(batchJob)
            
        
    def run(self):
        for (dcIndex, dataCenter) in self.dataCenters.dataCenters.items():
            dataCenter.scheduleJobs(ShorterVideosFirstScheduler.queueJobs, self)
            
        
    @staticmethod
    def queueJobs(scheduler, dcIndex, batchMachine):
        curQueue = scheduler.jobQueue[dcIndex]
        # optimize max duration limitation
        maxDuration = batchMachine.maxDuration
        if (maxDuration != None):
            if (scheduler.prioFactors == None and curQueue.getHead().duration > maxDuration):
                return [None, True]
                
            if (scheduler.shortVideoDuration == maxDuration and scheduler.queuedShortVideoJobs[dcIndex] == 0):
                return [None, True]
                
            
        # optimize max priority limitation
        maxPriority = batchMachine.maxPriority
        if (maxPriority != None):
            hasJobs = False
            for (prio, jobCount) in scheduler.queuedJobsPerPriority[dcIndex].items():
                if (jobCount != 0 and prio <= maxPriority):
                    hasJobs = True
                    break
                    
                
            if (not hasJobs):
                return [None, True]
                
            
        # start a job
        curJob = curQueue.walk(getMatchingJobCB, batchMachine)
        if (curJob != None):
            scheduler.queuedJobsPerPriority[dcIndex][curJob.getPriority()] -= 1
            if (curJob.duration <= scheduler.shortVideoDuration):
                scheduler.queuedShortVideoJobs[dcIndex] -= 1                
            
        continueLoop = (scheduler.jobQueue[dcIndex].getCount() != 0)
        return [curJob, continueLoop]
        
    def done(self):
        for subQueue in self.jobQueue.values():
            assert(subQueue.getCount() == 0)
            
        
    
class RelWaitTimeScheduler:
#WARNING: passing args by reference not supported (&$schedParams)
#WARNING: passing args by reference not supported (&$dataCenters)
    def __init__(self, schedParams, dataCenters):
        self.jobQueue = {0 : [],
			1 : []}
        self.dataCenters = dataCenters
        
    def queueJob(self, batchJob):
        dc = int(batchJob.getDc())
        self.jobQueue[dc].append(batchJob)
        
    @staticmethod
    def getHighestPriorityJobIndex(jobQueue):
        global currentTime, PARAMETERS
        bestPriority = None
        bestIndex = None
        for index in xrange(len(jobQueue)):
            curJob = jobQueue[index]
            if (currentTime > curJob.getCreatedAt(None)):
                waitTime = currentTime - curJob.getCreatedAt(None)
                
            else:
                waitTime = 0
                
            if (curJob.getFinishTime(None) > curJob.getQueueTime(None) + PARAMETERS['minProcessTime']):
                processTime = curJob.getFinishTime(None) - curJob.getQueueTime(None)
                
            else:
                processTime = PARAMETERS['minProcessTime']
                
            curPriority = waitTime / processTime
            if (bestPriority == None or curPriority > bestPriority):
                bestIndex = index
                bestPriority = curPriority
                
            
        return bestIndex
        
    def run(self):
        for (dcIndex, dataCenter) in self.dataCenters.dataCenters.items():
            if (len(self.jobQueue[dcIndex]) == 0):
                continue
                
            dataCenter.scheduleJobs(RelWaitTimeScheduler.queueJobs, self)
            
        
    @staticmethod
    def queueJobs(scheduler, dcIndex, batchMachine):
        curQueue = scheduler.jobQueue[dcIndex]
        bestIndex = RelWaitTimeScheduler.getHighestPriorityJobIndex(curQueue)
        curJob = curQueue[bestIndex]
        curQueue.pop(bestIndex)
        continueLoop = (len(scheduler.jobQueue[dcIndex]) != 0)
        return [curJob, continueLoop]
        
    def done(self):
        for subQueue in self.jobQueue.values():
            assert(len(subQueue) == 0)
            
        
    
class DummyBatchJob:
    def __init__(self, dc, priority, partnerId, duration, processingTime):
        global currentTime
        self.dc = dc
        self.priority = priority
        self.partnerId = partnerId
        self.duration = duration
        self.processingTime = processingTime
        self.id = random.randint(1000000, 2000000)
        self.entryId = random.randint(1000000, 2000000)
        self.createdAt = currentTime
        
    def getDc(self):
        return self.dc
        
    def getPriority(self):
        return self.priority
        
    def getPartnerId(self):
        return self.partnerId
        
    def getExecutionAttempts(self):
        return 1
        
    def getId(self):
        return self.id
        
    def getEntryId(self):
        return self.entryId
        
    def getCreatedAt(self, ignore):
        return self.createdAt
        
    def getQueueTime(self, ignore):
        return self.getCreatedAt(None)
        
    def getFinishTime(self, ignore):
        return self.getQueueTime(None) + self.processingTime
        
    def getStatus(self):
        return BatchJob.BATCHJOB_STATUS_FINISHED
        
    
#*******************************************************
# *		Simulation / Playback
# *******************************************************
class Simulation:
    def __init__(self, simulation):
        self.dataCenters = DataCenters(simulation['topology'])
        scheduler = simulation['scheduler']
        schedulerClass = scheduler['class']
        self.scheduler = globals()[schedulerClass](scheduler, self.dataCenters)
        self.dummyJobsDetails = valueOrNull(simulation, 'dummyJobsDetails')
        self.name = "%s/%s" % (scheduler['name'], self.dataCenters.name)
        if (self.dummyJobsDetails != None):
            self.name += "/%s" % (self.dummyJobsDetails['name'])
            
        self.stats = Statistics(self.name)
        
    def queueDummyJobs(self, details):
        global currentTime, PARAMETERS
        curTime = time.strftime('%Y-%m-%d %H:%M:%S')
        sys.stdout.write("%s Queuing dummy jobs...\n" % (curTime))
        for dcIndex in xrange(2):
            for index in xrange(details['jobCount']):
                duration = random.randint(details['minDuration'], details['maxDuration'])
                processingTime = duration * random.randint(details['minProcessFactor'], details['maxProcessFactor'])
                curJob = DummyBatchJob(
					dcIndex, 
					details['priority'], 
					PARAMETERS['dummyPartnerId'], 
					duration, 
					processingTime)
                self.stats.notifyJobQueued(curJob, currentTime)
                self.scheduler.queueJob(curJob)
                
            
        curTime = time.strftime('%Y-%m-%d %H:%M:%S')
        sys.stdout.write(curTime+" Queuing dummy jobs done...\n")
        
    def run(self, batchJobs, moreJobsLeft):
        global currentTime
        globals()["stats"] = self.stats
        batchJobIndex = 0
        
        while (True):
            # get next event time
            eventTimes = []
            if (batchJobIndex < len(batchJobs)):
                eventTimes.append(batchJobs[batchJobIndex].getCreatedAt(None))
                
            elif (moreJobsLeft):
                return
                
            nextCompleteTime = self.dataCenters.getNextCompleteTime()
            if (nextCompleteTime != None):
                eventTimes.append(nextCompleteTime)
                
            nextEventTime = None
            for eventTime in eventTimes:
                if (nextEventTime == None or eventTime < nextEventTime):
                    nextEventTime = eventTime
                    
                
            if (nextEventTime == None):
                break
                
            currentTime = nextEventTime
            if (self.dummyJobsDetails != None and
				self.dummyJobsDetails['queueTime'] <= currentTime):
                self.queueDummyJobs(self.dummyJobsDetails)
                self.dummyJobsDetails = None
                
            # queue jobs that were already created
            while (batchJobIndex < len(batchJobs) and
				batchJobs[batchJobIndex].getCreatedAt(None) <= currentTime):
                curJob = batchJobs[batchJobIndex]
                self.stats.notifyJobQueued(curJob, currentTime)
                self.scheduler.queueJob(curJob)
                batchJobIndex += 1
                
            # update machine statuses
            self.dataCenters.updateStatus()
            # run scheduling algorithm
            self.scheduler.run()
            
            
        self.scheduler.done()
        self.dataCenters.done()
        
    def getVars(self):
        return self.stats.getVars()
        
    def getCats(self):
        return self.stats.getCats()
        
    def getMeasures(self, cat, var):
        return self.stats.getMeasures(cat, var)
        
    
class ActualPlayback:
    def __init__(self):
        self.stats = Statistics('Actual')
        self.pendingJobs = SortedArray(ActualPlayback.getJobQueueTime)
        self.runningJobs = SortedArray(ActualPlayback.getJobFinishTime)
        self.name = 'Actual results'
        
    @staticmethod
    def getJobQueueTime(object, context):
        return object.getQueueTime(None)
        
    @staticmethod
    def getJobFinishTime(object, context):
        return object.getFinishTime(None)
        
    def addToPendingQueue(self, batchJob):
        self.pendingJobs.insert(batchJob)
        
    def addToRunningQueue(self, batchJob):
        self.runningJobs.insert(batchJob)
        
    def startJobs(self):
        global currentTime
        while (self.pendingJobs.getCount() != 0 and
				self.pendingJobs.getHead().getQueueTime(None) <= currentTime):
            selectedJob = self.pendingJobs.removeHead()
            self.stats.notifyJobStarted(selectedJob, selectedJob.getQueueTime(None))
            self.addToRunningQueue(selectedJob)
            
        
    def completeJobs(self):
        global currentTime
        while (self.runningJobs.getCount() != 0 and
				self.runningJobs.getHead().getFinishTime(None) <= currentTime):
            selectedJob = self.runningJobs.removeHead()
            self.stats.notifyJobCompleted(selectedJob, selectedJob.getQueueTime(None), selectedJob.getFinishTime(None))
            
        
    def run(self, batchJobs, moreJobsLeft):
        global currentTime
        if (len(batchJobs) == 0 and moreJobsLeft):
            return
            
        for batchJob in batchJobs:
            self.stats.notifyJobQueued(batchJob, currentTime)
            self.addToPendingQueue(batchJob)
            runUntil = batchJob.getCreatedAt(None)
            
        if (not moreJobsLeft):
            runUntil = None
            
        
        while (True):
            # get next event time
            nextEventTime = None
            if (self.pendingJobs.getCount() != 0):
                nextEventTime = self.pendingJobs.getHead().getQueueTime(None)
                
            if (self.runningJobs.getCount() != 0):
                nextCompleteTime = self.runningJobs.getHead().getFinishTime(None)
                if (nextEventTime == None or nextCompleteTime < nextEventTime):
                    nextEventTime = nextCompleteTime
                    
                
            if (nextEventTime == None):
                break
                
            if (runUntil != None and nextEventTime > runUntil):
                return
                
            # start jobs that were queued and complete jobs that were finished
            currentTime = nextEventTime
            self.startJobs()
            self.completeJobs()
            
            
        
    def getVars(self):
        return self.stats.getVars()
        
    def getCats(self):
        return self.stats.getCats()
        
    def getMeasures(self, cat, var):
        return self.stats.getMeasures(cat, var)
        
    
#*******************************************************
# *		Main
# *******************************************************
def runSimulationCallback(batchJob):
    global simulations, PARAMETERS
    if (batchJob.getQueueTime(None) == None or
		batchJob.getFinishTime(None) == None):
        return
        
    mediaInfo = mediaInfoPeer.retrieveByPK(batchJob.getData().getMediaInfoId())
    if (mediaInfo == None):
        return
        
    batchJob.duration = max(mediaInfo.getVideoDuration(), mediaInfo.getContainerDuration())
    if (batchJob.duration == None):
        batchJob.duration = 0
        
    else:
        batchJob.duration /= 1000
        
    if (PARAMETERS.has_key('manipulateJobsCallback')):
        PARAMETERS['manipulateJobsCallback']( batchJob)
        
    batchJobs = [batchJob]
    for simulation in simulations.values():
        simulation.run(batchJobs, True)
        
    
def createSimulations():
    global PARAMETERS, simulations
    simulations = {}
    for simulation in PARAMETERS['simulations']:
        if (simulation == 'actual'):
            curSimul = ActualPlayback()
            
        else:
            curSimul = Simulation(simulation)
            
        simulations[curSimul.name] = curSimul
        
    
def getVarsAndCats():
    global simulations
    vars = []
    cats = []
    for simulation in simulations.values():
        vars = vars + simulation.getVars()
        cats = cats + simulation.getCats()
        
    vars = list(set(vars))
    cats = list(set(cats))
    vars.sort()
    cats.sort()
    return [vars, cats]
    
def printResults(vars, cats):
    global simulations
    for var in vars:
        sys.stdout.write("%s\n===============\n" % (var))
        for cat in cats:
            if (endswith(cat, '_FF') and 
				var in ['runningJobs', 'queuedJobs']):
                # these vars are not calced correctly for FF categories
                continue
                
            sys.stdout.write("%s=>%s\n=-=-=-=-=-=-=-=-=-=\n" % (var, cat))
            for simulation in simulations.values():
                sys.stdout.write("%s\n--------------\n" % (simulation.name))
                measures = simulation.getMeasures(cat, var)
                for (name, value) in measures.items():
                    sys.stdout.write("%s: %s\n" % (name, value))
                    
                sys.stdout.write("\n")
                
            
        
    sys.stdout.write("\n")
    
def simulationMain(parameters):
    global PARAMETERS, simulations
    PARAMETERS = parameters
    sys.stdout.write("Started...\n")
    sys.stdout.write(repr(parameters))
    sys.stdout.write("\n")
    initializePropel()
    # create simulations
    createSimulations()
    # run simulations
    enumBatchJobs(
		parameters['startTime'], 
		parameters['endTime'], 
		runSimulationCallback)
    for simulation in simulations.values():
        simulation.run([], False)
        
    sys.stdout.write("Done !\n\n")
    # get list of variables and categories
    (vars, cats) = getVarsAndCats()
    # print the report
    printRunningJobsInfo(parameters['startTime'])
    printResults(vars, cats)
    return [vars, cats, simulations]
    

